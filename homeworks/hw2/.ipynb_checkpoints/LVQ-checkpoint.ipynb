{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelled Vector Quantaizer (LVQ) from scrach\n",
    "## Part One\n",
    "Remember LVQ algorithms? Well in this problem we would like to implement two LVQ algorithms fora binary classification task.\n",
    "\n",
    "* 1.  LVQ 1\n",
    "\n",
    "The dataset to evaluate your code is attached.  Please note that you should split the data into trainingand validation sets (9.0 ratio).  The last column is a label for each point.\n",
    "\n",
    "Please be advised, any use of python libraries, which have predefined algorithms is strictly prohibited.You should use numpy for your implementation (Tensorflow implementation has bonus score).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(r\"./data set.txt\", header=None)\n",
    "\n",
    "\n",
    "\n",
    "X = np.array([dataset[0],dataset[1],dataset[2],dataset[3]]).transpose()\n",
    "Y = np.array(dataset[4])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation description\n",
    "LVQ has six main steps as belows:\n",
    "1. Initialize weghts\n",
    "2. Repeat stages 2 to 6 while stop condition is not true\n",
    "3. For each input sample find nearest prototype vector using some destance measure as vector $W_j$\n",
    "4. Update $W_j$ like:\n",
    "    * if label = $W_j$ label then: $W_j = W_j + \\alpha \\left( t \\right) \\times (X - W_j)$\n",
    "    * if label != $W_j$ label then: $W_j = W_j - \\alpha \\left( t \\right) \\times (X - W_j)$\n",
    "5. Reduce learning rate ($\\alpha$)\n",
    "6. check stop condition\n",
    "    * Stop condition could be number of times that we give input data to the network\n",
    "\n",
    "As observed in the steps, we need a distance measure to find the nearest prototype vector to the input sample. For simplicity, we could choose *euclidean distance* as a distance measure for our implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(c,x):\n",
    "    return sqrt(np.dot((c-x),(c-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing needed for the LVQ algorithm, a number of prototype vectors for the problem. Choosing prototype vectors could be a challenging choice as they affect our overall performance and final accuracy score. By choosing these vectors with prior knowledge of the training data, we could achieve better results instead of choosing blindly.\n",
    " \n",
    "As it is a homework and again for fewer context length, we assume two prototype vectors for *negative* and *positive* classes, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.19548133  4.08533252 12.53875772  1.40327676]\n",
      " [ 4.97449953  2.79617278  8.93597108 13.90703441]]\n"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(2,4)*X_train.max()\n",
    "y_w = np.array([0,1])\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the requirements, let's write the LVQ class that uses our *dataset* and prototype vector to fit the model with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ:\n",
    "    \n",
    "    def __init__(self, w, w_label):\n",
    "        if(w.shape[0] != w_label.shape[0]):\n",
    "            raise ValueError(\"Vectors and labels dont't have the same length.\")\n",
    "        self.w = np.array(w)\n",
    "        self.w_label = np.array(w_label)\n",
    "        \n",
    "    def __euclideanDistance(self, c,x):\n",
    "        return sqrt(np.dot((c-x),(c-x)))\n",
    "    \n",
    "    def __findWinner(self, x):\n",
    "        winnerIdx = 0\n",
    "        nearestDistance = 1000000\n",
    "        for i in range(w.shape[0]):\n",
    "            distance = self.__euclideanDistance(x, w[i])\n",
    "            if(distance < nearestDistance):\n",
    "                nearestDistance = distance\n",
    "                winnerIdx = i\n",
    "        return winnerIdx\n",
    "    \n",
    "    def __update(self, x, x_label, winnerIdx):\n",
    "        \n",
    "        delta = (x - self.w[winnerIdx])\n",
    "        if(x_label == self.w_label[winnerIdx]):\n",
    "            self.w[winnerIdx] = self.w[winnerIdx] + (delta*self.alpha)\n",
    "        else:\n",
    "            self.w[winnerIdx] = self.w[winnerIdx] - (delta*self.alpha)\n",
    "\n",
    "\n",
    "    def fit(self, X, Y, alpha=0.5, epoch=10):\n",
    "        self.alpha = alpha \n",
    "        if(X.shape[0] != Y.shape[0]):\n",
    "            raise ValueError(\"Vectors and labels dont't have the same length.\")\n",
    "        for e in tqdm(range(epoch)):\n",
    "            self.alpha = alpha*(1-e/epoch)\n",
    "            l = np.arange(X.shape[0])\n",
    "            np.random.shuffle(l)            \n",
    "            for i in l:\n",
    "                x = X[i]\n",
    "                y = Y[i]\n",
    "                winnerIdx = self.__findWinner(x)\n",
    "                self.__update(x, y, winnerIdx)\n",
    "                \n",
    "    def predict(self, X):\n",
    "        Y_predict = []\n",
    "        for x in X:\n",
    "            winnerIdx = self.__findWinner(x)\n",
    "            Y_predict += [self.w_label[winnerIdx]]\n",
    "        return np.array(Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a222977a364e17b96a19ab6a8d53cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.5579710144927537\n"
     ]
    }
   ],
   "source": [
    "lvq = LVQ(w, y_w)\n",
    "lvq.fit(X_train, Y_train, alpha=1, epoch=10)\n",
    "Y_pred = lvq.predict(X_test)\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By initializing prototype vectors having prior knowledge about the data, we could achieve better results. To test this fact, let's consider prototype vectors as a negative sample and a positive sample from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42210b2a089a4cc79454d63e9dd19cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6811594202898551\n"
     ]
    }
   ],
   "source": [
    "pIdx = 0 # Posetive sample index\n",
    "nIdx = 0 # Negative sample index\n",
    "\n",
    "for i in range(Y_train.shape[0]):\n",
    "    if(Y_train[i] == 0):\n",
    "        nIdx = i\n",
    "        break\n",
    "for i in range(Y_train.shape[0]):\n",
    "    if(Y_train[i] == 1):\n",
    "        pIdx = i\n",
    "        break\n",
    "        \n",
    "w = np.array([X_train[nIdx],X_train[pIdx]])\n",
    "y_w = np.array([0,1])\n",
    "\n",
    "lvq = LVQ(w, y_w)\n",
    "lvq.fit(X_train, Y_train, alpha=1, epoch=10)\n",
    "Y_pred = lvq.predict(X_test)\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed, by choosing prototype vectors as the first and sample of each class in our training set, the accuracy increses. for better results, we could choose much better samples with some preprocessing on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
